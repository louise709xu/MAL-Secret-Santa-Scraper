{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from requests import get\n",
    "from requests.exceptions import RequestException\n",
    "from contextlib import closing\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Links to forum posts\n",
    "index_link = \"https://myanimelist.net/\"\n",
    "topic_link_img = \"https://myanimelist.net/forum/?topicid=1753247\"\n",
    "topic_link_rec = \"https://myanimelist.net/forum/?topicid=1753246\"\n",
    "\n",
    "pages_img = 3\n",
    "pages_rec = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HTML Request Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def simple_get(url):\n",
    "    \"\"\"\n",
    "    Attempts to get the content at `url` by making an HTTP GET request.\n",
    "    If the content-type of response is some kind of HTML/XML, return the\n",
    "    text content, otherwise return None.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with closing(get(url, stream=True)) as resp:\n",
    "            if is_good_response(resp):\n",
    "                return resp.content\n",
    "            else:\n",
    "                return None\n",
    "\n",
    "    except RequestException as e:\n",
    "        log_error('Error during requests to {0} : {1}'.format(url, str(e)))\n",
    "        return None\n",
    "\n",
    "\n",
    "def is_good_response(resp):\n",
    "    \"\"\"\n",
    "    Returns True if the response seems to be HTML, False otherwise.\n",
    "    \"\"\"\n",
    "    content_type = resp.headers['Content-Type'].lower()\n",
    "    return (resp.status_code == 200 \n",
    "            and content_type is not None \n",
    "            and content_type.find('html') > -1)\n",
    "\n",
    "\n",
    "def log_error(e):\n",
    "    \"\"\"\n",
    "    It is always a good idea to log errors. \n",
    "    This function just prints them, but you can\n",
    "    make it do anything.\n",
    "    \"\"\"\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraper(url, version, santa_list):\n",
    "    \n",
    "    # Get posts from url\n",
    "    raw_html = simple_get(url)\n",
    "    html = BeautifulSoup(raw_html, 'html.parser')\n",
    "    \n",
    "    posts = html.find_all(\"div\", class_=\"forum_border_around \")\n",
    "    \n",
    "    # Parse each post for info\n",
    "    for i in posts: \n",
    "        \n",
    "        links = i.find_all('a')\n",
    "\n",
    "        post_num = links[2].get_text()\n",
    "        if post_num == '1': continue\n",
    "        \n",
    "        post_id = links[2].attrs[\"href\"]\n",
    "        post_link = topic_link_img + post_id\n",
    "\n",
    "        user_name = links[3].strong.get_text()\n",
    "        user_link = index_link + \"profile/\" + user_name\n",
    "\n",
    "        post_content = i.find(\"div\", id=\"message\"+post_id[4:]).get_text()\n",
    "        result = re.findall(r':(.*?)\\n', post_content)\n",
    "        \n",
    "        # Img specific parsing\n",
    "        if version == \"img\":\n",
    "            if len(result) < 6:\n",
    "                img_type       = \"\"\n",
    "                user_skill_lvl = \"\"\n",
    "                gift_skill_lvl = \"\"\n",
    "                prev_imgs      = \"\"\n",
    "            else:\n",
    "                img_type       = result[0]\n",
    "                user_skill_lvl = result[3]\n",
    "                gift_skill_lvl = result[4]\n",
    "                prev_imgs      = result[5]\n",
    "            user_form = [post_num, post_link, user_name, user_link, \n",
    "                         img_type, user_skill_lvl, gift_skill_lvl, prev_imgs]\n",
    "            \n",
    "        # Rec specific parsing\n",
    "        if version == \"rec\":\n",
    "            if len(result) < 8:\n",
    "                rec_type      = \"\"\n",
    "                likes         = \"\"\n",
    "                dislikes      = \"\"\n",
    "                num_completed = \"\"\n",
    "            else:\n",
    "                rec_type      = result[0]\n",
    "                likes         = result[2]\n",
    "                dislikes      = result[3]\n",
    "                num_completed = result[6]\n",
    "            user_form = [post_num, post_link, user_name, user_link, \n",
    "                         rec_type, likes, dislikes, num_completed]\n",
    "            \n",
    "        santa_list.append(user_form)\n",
    "        \n",
    "    return santa_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "post_num                                                          2\n",
       "post_link         https://myanimelist.net/forum/?topicid=1753247...\n",
       "user_name                                                   Dar9586\n",
       "user_link                   https://myanimelist.net/profile/Dar9586\n",
       "img_type                                               Profile pic \n",
       "user_skill_lvl                                             Advanced\n",
       "gift_skill_lvl                                                  Yes\n",
       "prev_imgs                           https://imgur.com/gallery/gltq9\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Image Format\n",
    "#   Type of image (profile pic, about me, forum avi, sig, profile set, forum set, or surprise me): \n",
    "#   Likes (artists, characters, tags, etc.): \n",
    "#   Dislikes (artists, characters, tags, etc.): \n",
    "#   Your image editing skill level (Beginner, Intermediate, or Advanced): \n",
    "#   Would you like to receive an image of the same level? (Yes or Surprise Me): \n",
    "#   Link(s) to some previous images you've used: \n",
    "#   Link to your profile: \n",
    "\n",
    "header = ['post_num', 'post_link', 'user_name', 'user_link', 'img_type', 'user_skill_lvl', 'gift_skill_lvl', 'prev_imgs']\n",
    "santa_list_img = [[None] * len(header)]\n",
    "\n",
    "for i in range(pages_img):\n",
    "    url = topic_link_img + \"&show=\" + str(50 * i)\n",
    "    scraper(url, \"img\", santa_list_img)\n",
    "\n",
    "df_img = pd.DataFrame(santa_list_img, columns=header)\n",
    "df_img = df_img.drop([0])\n",
    "# export_csv = df_img.to_csv (r'.\\secret_santa_list.csv', index = None, header=True) \n",
    "\n",
    "df_img.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "post_num                                                         2\n",
       "post_link        https://myanimelist.net/forum/?topicid=1753247...\n",
       "user_name                                          ScarredSceptile\n",
       "user_link          https://myanimelist.net/profile/ScarredSceptile\n",
       "rec_type                                                          \n",
       "likes                                                             \n",
       "dislikes                                                          \n",
       "num_completed                                                     \n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recommendation Format\n",
    "#   Rec type (anime, manga, either, or both):\n",
    "#   Min-Max length (episodes/volumes): \n",
    "#   Likes (genres, demographics, themes): \n",
    "#   Dislikes (genres, demographics, themes):\n",
    "#   Any fansub/fanscan restrictions? (i.e. must it be available on CR, in print, etc.): \n",
    "#   Can the recommendation be on your Plan to Watch list? (Yes or No): \n",
    "#   Number of Completed entries on your anime/manga list: \n",
    "#   Link to anime/manga list: \n",
    "\n",
    "header = ['post_num', 'post_link', 'user_name', 'user_link', 'rec_type', 'likes', 'dislikes', 'num_completed']\n",
    "santa_list_rec = [[None] * len(header)]\n",
    "\n",
    "for i in range(pages_rec):\n",
    "    url = topic_link_rec + \"&show=\" + str(50 * i)\n",
    "    scraper(url, \"rec\", santa_list_rec)\n",
    "\n",
    "df_rec = pd.DataFrame(santa_list_rec, columns=header)\n",
    "df_rec = df_rec.drop([0])\n",
    "# export_csv = df_rec.to_csv (r'.\\secret_santa_list.csv', index = None, header=True) \n",
    "\n",
    "df_rec.iloc[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
