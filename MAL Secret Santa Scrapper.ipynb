{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from requests import get\n",
    "from requests.exceptions import RequestException\n",
    "from contextlib import closing\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Links to forum posts\n",
    "index_link = \"https://myanimelist.net/\"\n",
    "topic_link_anime = \"https://myanimelist.net/forum/?topicid=1812367\"\n",
    "topic_link_manga = \"https://myanimelist.net/forum/?topicid=1812368\"\n",
    "topic_link_image = \"https://myanimelist.net/forum/?topicid=1812369\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HTML Request Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_get(url):\n",
    "    \"\"\"\n",
    "    Attempts to get the content at `url` by making an HTTP GET request.\n",
    "    If the content-type of response is some kind of HTML/XML, return the\n",
    "    text content, otherwise return None.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with closing(get(url, stream=True)) as resp:\n",
    "            if is_good_response(resp):\n",
    "                return resp.content\n",
    "            else:\n",
    "                return None\n",
    "\n",
    "    except RequestException as e:\n",
    "        log_error('Error during requests to {0} : {1}'.format(url, str(e)))\n",
    "        return None\n",
    "\n",
    "\n",
    "def is_good_response(resp):\n",
    "    \"\"\"\n",
    "    Returns True if the response seems to be HTML, False otherwise.\n",
    "    \"\"\"\n",
    "    content_type = resp.headers['Content-Type'].lower()\n",
    "    return (resp.status_code == 200 \n",
    "            and content_type is not None \n",
    "            and content_type.find('html') > -1)\n",
    "\n",
    "\n",
    "def log_error(e):\n",
    "    \"\"\"\n",
    "    It is always a good idea to log errors. \n",
    "    This function just prints them, but you can\n",
    "    make it do anything.\n",
    "    \"\"\"\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraper(url, version, santa_list):\n",
    "    \n",
    "    # Get posts from url\n",
    "    raw_html = simple_get(url)\n",
    "    html = BeautifulSoup(raw_html, 'html.parser')\n",
    "\n",
    "    posts = html.find_all(\"div\", class_=\"forum_border_around\")\n",
    "    \n",
    "    # Parse each post for info\n",
    "    for i in posts: \n",
    "        \n",
    "        links = i.find_all('a')\n",
    "\n",
    "        post_num = links[2].get_text()\n",
    "        if post_num == '1': continue\n",
    "        \n",
    "        post_id = links[2].attrs[\"href\"]\n",
    "        post_link = url + post_id\n",
    "\n",
    "        user_name = links[3].strong.get_text()\n",
    "        user_link = index_link + \"profile/\" + user_name\n",
    "\n",
    "        post_content = i.find(\"div\", id=\"message\"+post_id[4:]).get_text()\n",
    "        result = re.findall(r':(.*?)\\n', post_content)\n",
    "\n",
    "        # Img specific parsing\n",
    "        if version == \"img\":\n",
    "            if len(result) < 6:\n",
    "                img_type       = \"\"\n",
    "                user_skill_lvl = \"\"\n",
    "                gift_skill_lvl = \"\"\n",
    "                prev_imgs      = \"\"\n",
    "            else:\n",
    "                img_type       = result[0]\n",
    "                user_skill_lvl = result[3]\n",
    "                gift_skill_lvl = result[4]\n",
    "                prev_imgs      = result[5]\n",
    "            user_form = [post_num, post_link, user_name, user_link, \n",
    "                         img_type, user_skill_lvl, gift_skill_lvl, prev_imgs]\n",
    "            \n",
    "        elif version == \"anime\" or \"manga\":\n",
    "            # Get posts from url\n",
    "            #profile_html = simple_get(user_link)\n",
    "            profile_html = None\n",
    "            if profile_html is None:\n",
    "                watching      = \"\"\n",
    "                completed     = \"\"\n",
    "                on_hold       = \"\"\n",
    "                dropped       = \"\"\n",
    "                plan_to_watch = \"\"\n",
    "            else:\n",
    "                profile = BeautifulSoup(profile_html, 'html.parser')\n",
    "\n",
    "                stats_container = profile.find_all(\"ul\", class_=\"stats-status\")\n",
    "\n",
    "                if version == \"anime\":\n",
    "                    stats = stats_container[0].find_all(\"span\", class_=\"di-ib\")\n",
    "                    watching      = stats[0].get_text()\n",
    "                    completed     = stats[1].get_text()\n",
    "                    on_hold       = stats[2].get_text()\n",
    "                    dropped       = stats[3].get_text()\n",
    "                    plan_to_watch = stats[4].get_text()\n",
    "                else:\n",
    "                    stats = stats_container[1].find_all(\"span\", class_=\"di-ib\")\n",
    "                    watching      = stats[0].get_text()\n",
    "                    completed     = stats[1].get_text()\n",
    "                    on_hold       = stats[2].get_text()\n",
    "                    dropped       = stats[3].get_text()\n",
    "                    plan_to_watch = stats[4].get_text()\n",
    "                \n",
    "            if len(result) < 7:\n",
    "                likes         = \"\"\n",
    "                dislikes      = \"\"\n",
    "                num_completed = \"\"\n",
    "            else:\n",
    "                likes         = result[1]\n",
    "                dislikes      = result[2]\n",
    "                completed     = result[5]\n",
    "            user_form = [post_num, post_link, user_name, user_link, \n",
    "                         likes, dislikes, watching, completed, on_hold, \n",
    "                         dropped, plan_to_watch]\n",
    "            \n",
    "        santa_list.append(user_form)\n",
    "    return santa_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "post_num                                                          2\n",
       "post_link         https://myanimelist.net/forum/?topicid=1812369...\n",
       "user_name                                                   Lashkjx\n",
       "user_link                   https://myanimelist.net/profile/Lashkjx\n",
       "img_type                                                Profile set\n",
       "user_skill_lvl                                             Advanced\n",
       "gift_skill_lvl                                                  Yes\n",
       "prev_imgs          My collection of images I used and my gifts f...\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Image Format\n",
    "#   Type of image (profile pic, about me, forum avi, sig, profile set, forum set, or surprise me): \n",
    "#   Likes (artists, characters, tags, etc.): \n",
    "#   Dislikes (artists, characters, tags, etc.): \n",
    "#   Your image editing skill level (Beginner, Intermediate, or Advanced): \n",
    "#   Would you like to receive an image of the same level? (Yes or Surprise Me): \n",
    "#   Link(s) to some previous images you've used: \n",
    "#   Link to your profile: \n",
    "\n",
    "header = ['post_num', 'post_link', 'user_name', 'user_link', \n",
    "          'img_type', 'user_skill_lvl', 'gift_skill_lvl', 'prev_imgs']\n",
    "santa_list_img = [[None] * len(header)]\n",
    "\n",
    "page_num = 1\n",
    "url = topic_link_image + \"&show=\" + str(50 * (page_num-1))\n",
    "scraper(url, \"img\", santa_list_img)\n",
    "\n",
    "df_img = pd.DataFrame(santa_list_img, columns=header)\n",
    "df_img = df_img.drop([0])\n",
    "export_csv = df_img.to_csv (r'.\\secret_santa_list_image.csv', index = None, header=True) \n",
    "\n",
    "df_img.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendation (Anime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "post_num                                                        51\n",
       "post_link        https://myanimelist.net/forum/?topicid=1812367...\n",
       "user_name                                                   marzus\n",
       "user_link                   https://myanimelist.net/profile/marzus\n",
       "likes                                                           \\r\n",
       "dislikes                                             Music, Top 20\n",
       "watching                                                          \n",
       "completed                                                      109\n",
       "on_hold                                                           \n",
       "dropped                                                           \n",
       "plan_to_watch                                                     \n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recommendation Format\n",
    "#   Min-Max length (episodes):\n",
    "#   Likes (genres, demographics, themes):\n",
    "#   Dislikes (genres, demographics, themes): \n",
    "#   Any sub/stream restrictions? (e.g. must it be available on CR):\n",
    "#   Can the recommendation be on your Plan to Watch list? (Yes or No):\n",
    "#   Number of Completed entries on your anime list:\n",
    "#   Does your list include everything you've seen (except childhood anime)?:\n",
    "#   Link to anime list:\n",
    "\n",
    "header = ['post_num', 'post_link', 'user_name', 'user_link', \n",
    "          'likes', 'dislikes', 'watching', 'completed', 'on_hold', 'dropped', 'plan_to_watch']\n",
    "santa_list_anime = [[None] * len(header)]\n",
    "\n",
    "page_num = 2\n",
    "url = topic_link_anime + \"&show=\" + str(50 * (page_num-1))\n",
    "scraper(url, \"anime\", santa_list_anime)\n",
    "\n",
    "df_anime = pd.DataFrame(santa_list_anime, columns=header)\n",
    "df_anime = df_anime.drop([0])\n",
    "export_csv = df_anime.to_csv (r'.\\secret_santa_list_anime.csv', index=None, header=True) \n",
    "\n",
    "df_anime.iloc[0]\n",
    "#df_anime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendation (Manga)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "7 columns passed, passed data had 11 columns",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-fd558c74a486>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mscraper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"manga\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msanta_list_manga\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mdf_manga\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msanta_list_manga\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[0mdf_manga\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_manga\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mexport_csv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_manga\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34mr'.\\secret_santa_list_manga.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    433\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mis_named_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m                         \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fields\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m                     \u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m                     \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mto_arrays\u001b[1;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[0;32m    402\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m         return _list_to_arrays(data, columns, coerce_float=coerce_float,\n\u001b[1;32m--> 404\u001b[1;33m                                dtype=dtype)\n\u001b[0m\u001b[0;32m    405\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMapping\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m         return _list_of_dict_to_arrays(data, columns,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_list_to_arrays\u001b[1;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[0;32m    434\u001b[0m         \u001b[0mcontent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_object_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m     return _convert_object_array(content, columns, dtype=dtype,\n\u001b[1;32m--> 436\u001b[1;33m                                  coerce_float=coerce_float)\n\u001b[0m\u001b[0;32m    437\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_convert_object_array\u001b[1;34m(content, columns, coerce_float, dtype)\u001b[0m\n\u001b[0;32m    490\u001b[0m             raise AssertionError('{col:d} columns passed, passed data had '\n\u001b[0;32m    491\u001b[0m                                  '{con} columns'.format(col=len(columns),\n\u001b[1;32m--> 492\u001b[1;33m                                                         con=len(content)))\n\u001b[0m\u001b[0;32m    493\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    494\u001b[0m     \u001b[1;31m# provide soft conversion of object dtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: 7 columns passed, passed data had 11 columns"
     ]
    }
   ],
   "source": [
    "# Recommendation Format\n",
    "#   Min-Max length (episodes):\n",
    "#   Likes (genres, demographics, themes):\n",
    "#   Dislikes (genres, demographics, themes): \n",
    "#   Any sub/stream restrictions? (e.g. must it be available on CR):\n",
    "#   Can the recommendation be on your Plan to Watch list? (Yes or No):\n",
    "#   Number of Completed entries on your anime list:\n",
    "#   Does your list include everything you've seen (except childhood anime)?:\n",
    "#   Link to anime list:\n",
    "\n",
    "header = ['post_num', 'post_link', 'user_name', 'user_link', \n",
    "          'likes', 'dislikes', 'watching', 'completed', 'on_hold', 'dropped', 'plan_to_read']\n",
    "santa_list_manga = [[None] * len(header)]\n",
    "\n",
    "page_num = 1\n",
    "url = topic_link_manga + \"&show=\" + str(50 * (page_num-1))\n",
    "scraper(url, \"manga\", santa_list_manga)\n",
    "\n",
    "df_manga = pd.DataFrame(santa_list_manga, columns=header)\n",
    "df_manga = df_manga.drop([0])\n",
    "export_csv = df_manga.to_csv (r'.\\secret_santa_list_manga.csv', index=None, header=True) \n",
    "\n",
    "df_manga.iloc[0]\n",
    "#df_manga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
